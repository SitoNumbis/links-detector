{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_objects_detector_v5__public.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C6RmYsKrEvV"
      },
      "source": [
        "# üìñ üëÜüèª Printed Links Detection Using TensorFlow 2 Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNeiUTuPa-K7"
      },
      "source": [
        "![Links Detector Cover](https://raw.githubusercontent.com/trekhleb/links-detector/master/articles/printed_links_detection/assets/01-banner.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIkPgKIWsHiO"
      },
      "source": [
        "## üìÉ TL;DR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJedZpEkSKYq"
      },
      "source": [
        "_In this article we will start solving the issue of making the printed links (i.e. in a book or in a magazine) clickable via your smartphone camera._\n",
        "\n",
        "We will use [TensorFlow 2 Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) to train a custom object detector model to find a position and a bounding box of the sub-string `https://` in the text image (i.e. in smartphone camera stream).\n",
        "\n",
        "The text of each link will be recognized by using [Tesseract](https://tesseract.projectnaptha.com/) library. The recognition part will not be covered in this article but you may find the complete code example in üìù [**links-detector repository**](https://github.com/trekhleb/links-detector).   \n",
        "\n",
        "> üöÄ [**Launch Links Detector demo**](https://trekhleb.github.io/links-detector/) from your smartphone to see the final result.\n",
        "\n",
        "Here is how the final solution works:\n",
        "\n",
        "![Links Detector Demo](https://raw.githubusercontent.com/trekhleb/links-detector/master/articles/printed_links_detection/assets/03-links-detector-demo.gif)\n",
        "\n",
        "> ‚ö†Ô∏è Currently the application is in _experimental_ _Alpha_ stage and has [many issues and limitations](https://github.com/trekhleb/links-detector/issues?q=is%3Aopen+is%3Aissue+label%3Aenhancement). So don't raise your expectations bar to high until these issues are resolved ü§∑üèª‚Äç. The pruspose of the article is more about learning how to work with TensorFlow 2 Object Detection API rather than comming up with a production ready application."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlkOLNbOsajd"
      },
      "source": [
        "## ü§∑üèª‚Äç‚ôÇÔ∏è The Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucfFZFofSSTx"
      },
      "source": [
        "So you read a book or a magazine and see the links like `https://tensorflow.org/` or `https://some-url.com/which/may/be/longer?and_with_params=true`, but you can't click on them since they are printed. To visit these links you need to start typing them character by character in the browser's address bar, which may be pretty annoying and error prone.\n",
        "\n",
        "![Printed Links](https://raw.githubusercontent.com/trekhleb/links-detector/master/articles/printed_links_detection/assets/02-printed-links.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj7Gc-KVs4q6"
      },
      "source": [
        "## üí° Possible Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob8k5gcfixDd"
      },
      "source": [
        "Similarly to QR-code detection we may try to \"teach\" the smartphone to _detect_ and _recognize_ printed links for us and also to make them _clickable_. This way you'll do just one click instead of multiple keystrokes. Your operational complexity goes from `O(N)` to `O(1)`.\n",
        "\n",
        "![Links Detector Demo](https://raw.githubusercontent.com/trekhleb/links-detector/master/articles/printed_links_detection/assets/03-links-detector-demo.gif)\n",
        "\n",
        "**Solution requirements**:\n",
        "\n",
        "- Detection and recognition processes should have **close**-to-real-time performance (i.e. at least 0.5-1 frames per seccond).\n",
        "- Only English text for now\n",
        "- Only a black text on a white background for now\n",
        "- Only `https://` links for now (not `http://`,not `ftp://`, ...) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4orlNJkZs7vB"
      },
      "source": [
        "## üß© Solution Breakdown\n",
        "\n",
        "- Technichal details on how the solution may be achieved\n",
        "- Why TensorFlow, why Object Detection API\n",
        "- Problems that needs to be solved (custom objects, well-known models don't work, small objects, real-time)\n",
        "- Serverless, working on Mobile solution (why no backend? why lightweight model?)\n",
        "- Possible models review, why MobileNet\n",
        "- The issue with the Dataset (there is none)\n",
        "- I'm just learning and don't have too much of experience, wanted to experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VoRXizCNC-d"
      },
      "source": [
        "\n",
        "\n",
        "Let's assume that we want to achieve close-to-real-time performance.\n",
        "\n",
        "The task of finding the links on the image and making the mclickable may be split into two parts:\n",
        "\n",
        "1. Links **detection** (finding the position of the links)\n",
        "2. Links **recognition** (recognizing the text of the links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJQpRyWcud-r"
      },
      "source": [
        "## üìù Creating the Dataset Manually\n",
        "\n",
        "- Making pictures of the book\n",
        "- What tools to use to add bounding boxes\n",
        "- How to convert to protobuf\n",
        "- Issues with custom dataset (fonts, colors, bolds, underlined, etc.)\n",
        "- Train/test split approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H9ubdH7ZQqv"
      },
      "source": [
        "### üåÖ Preprocessing the data\n",
        "\n",
        "- Data preprocessing: resize, crop square, color adjustment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_0iXNZPZWLz"
      },
      "source": [
        "### üîñ Labeling the dataset\n",
        "\n",
        "- How to use LabelImg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKZgmaG6Zfbb"
      },
      "source": [
        "### üóú Exporting the dataset\n",
        "\n",
        "- Protobuf (the way of storing the dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLAAnasyvBhS"
      },
      "source": [
        "## üìö Generating the Dataset Automatically (?)\n",
        "\n",
        "- Automated way of generating the dataset\n",
        "- Train/test split approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdk05ymSO7WK"
      },
      "source": [
        "## üìñ Exploring the Dataset\n",
        "\n",
        "- Preview images with detection boxes\n",
        "- Number of images (why is this enough)\n",
        "- Do we need to preprocess the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0t-B7net2gA"
      },
      "source": [
        "## üõ† Installing Object Detection API \n",
        "\n",
        "- What is object detection API\n",
        "- Why it will simplify our lives\n",
        "- How it may be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edimSsPB0eaJ",
        "outputId": "29046f3e-6e2d-4873-c9fc-b1fbd5df97ce"
      },
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1e2BNri16Nq",
        "outputId": "52d59145-5c68-4186-eea2-9009663e2b94"
      },
      "source": [
        "ls -la models"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 72\n",
            "drwxr-xr-x  8 root root  4096 Nov 21 17:22 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x  1 root root  4096 Nov 21 17:24 \u001b[01;34m..\u001b[0m/\n",
            "-rw-r--r--  1 root root   337 Nov 21 17:22 AUTHORS\n",
            "-rw-r--r--  1 root root  1015 Nov 21 17:22 CODEOWNERS\n",
            "drwxr-xr-x  2 root root  4096 Nov 21 17:22 \u001b[01;34mcommunity\u001b[0m/\n",
            "-rw-r--r--  1 root root   390 Nov 21 17:22 CONTRIBUTING.md\n",
            "drwxr-xr-x  8 root root  4096 Nov 21 17:22 \u001b[01;34m.git\u001b[0m/\n",
            "drwxr-xr-x  3 root root  4096 Nov 21 17:22 \u001b[01;34m.github\u001b[0m/\n",
            "-rw-r--r--  1 root root  1104 Nov 21 17:22 .gitignore\n",
            "-rw-r--r--  1 root root  1115 Nov 21 17:22 ISSUES.md\n",
            "-rw-r--r--  1 root root 11405 Nov 21 17:22 LICENSE\n",
            "drwxr-xr-x 12 root root  4096 Nov 21 17:22 \u001b[01;34mofficial\u001b[0m/\n",
            "drwxr-xr-x  3 root root  4096 Nov 21 17:22 \u001b[01;34morbit\u001b[0m/\n",
            "-rw-r--r--  1 root root  3668 Nov 21 17:22 README.md\n",
            "drwxr-xr-x 23 root root  4096 Nov 21 17:22 \u001b[01;34mresearch\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfJpqVKg1aIH"
      },
      "source": [
        "%%bash\n",
        "cd ./models/research\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzM7civf12Gw",
        "outputId": "43ee10db-1784-4407-f3b6-1fa2d7aee6e0"
      },
      "source": [
        "%%bash\n",
        "cd ./models/research\n",
        "cp ./object_detection/packages/tf2/setup.py .\n",
        "pip install . --quiet"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR: multiprocess 0.70.10 has requirement dill>=0.3.2, but you'll have dill 0.3.1.1 which is incompatible.\n",
            "ERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.0 which is incompatible.\n",
            "ERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\n",
            "ERROR: apache-beam 2.25.0 has requirement avro-python3!=1.9.2,<1.10.0,>=1.8.1; python_version >= \"3.0\", but you'll have avro-python3 1.10.0 which is incompatible.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nQV0aWtuFpV"
      },
      "source": [
        "## ‚¨áÔ∏è Downloading Pre-Trained Model\n",
        "\n",
        "- Model detection Zoo review\n",
        "- What models we could use possibly\n",
        "- Why I've picked the MobileNet model\n",
        "- Diagram of the model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LpKaPIqPWph"
      },
      "source": [
        "## üèÑüèª‚Äç‚ôÇÔ∏è Trying the Model (Inference)\n",
        "\n",
        "- Show that model works for general purpose classes\n",
        "- Show that model doesn't work for custom objects (links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7triRLeP-_K"
      },
      "source": [
        "## üìà Setting Up TensorBoard\n",
        "\n",
        "- Why do we need it (for debugging)\n",
        "- What we will monitor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhU74WMHQH1E"
      },
      "source": [
        "## üë®‚Äçüéì Transfer Learning\n",
        "\n",
        "- What is transfer learning\n",
        "- Why don't we train the model from scratch\n",
        "- Allows us to use small dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7nFZjHUQR4A"
      },
      "source": [
        "### ‚öôÔ∏è Configuring the Detection Pipeline\n",
        "\n",
        "- Performance issues: batch size\n",
        "- Starting not from scratch: checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA_QoEhzQHCT"
      },
      "source": [
        "### üèãüèª‚Äç‚ôÇÔ∏è Model Training\n",
        "\n",
        "- Error prone: saving checkpoints\n",
        "- How many epochs\n",
        "- Monitoring the performance while training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7OZozAHQklI"
      },
      "source": [
        "### üöÄ Evaluating the Model\n",
        "\n",
        "- Checking how accurate our model is on test dataset\n",
        "- Are we good with performance, should we save the model?\n",
        "- It is not a general purpose anymore, does it recognize our custom objects?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMiDAvqTQvg8"
      },
      "source": [
        "## üóú Exporting the Model\n",
        "\n",
        "- Saving the model to the file for further re-use\n",
        "- Show the list of files, how the model looks like on dics\n",
        "- What the size of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlliMpvuQyUz"
      },
      "source": [
        "## üöÄ Evaluating the Exported Model\n",
        "\n",
        "- Example of how to use the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juyv3FMkQ4qO"
      },
      "source": [
        "## üóú Converting the Model for Web\n",
        "\n",
        "- What formats are sutable for the web\n",
        "- Few words about Tensorflow.js\n",
        "- Show list of exported files - how model looks like on disc\n",
        "- What the size of the model\n",
        "- Why it is split in chucnks and how they are connected (via model.json)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B8JU1UYzvBy",
        "outputId": "91b29075-0371-4018-e7a9-fbe08fc5055a"
      },
      "source": [
        "pip install tensorflowjs --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20kB 12.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 30kB 9.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 51kB 4.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 61kB 5.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 4.1MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |‚ñà‚ñà‚ñà‚ñè                            | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 20kB 20.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 30kB 16.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 40kB 14.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 51kB 11.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 61kB 11.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 71kB 7.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112kB 8.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhqXJkIpRF1A"
      },
      "source": [
        "## ü§î Conclusions\n",
        "\n",
        "- I'm just an amatour\n",
        "- Links to demo app\n",
        "- Issues and limitations of this approach\n",
        "- Links to my ML repositories that thy might like"
      ]
    }
  ]
}