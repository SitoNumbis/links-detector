{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_objects_detector_v5__public.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C6RmYsKrEvV"
      },
      "source": [
        "# üìñ üëÜüèª Printed Links Detection Using TensorFlow 2 Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNeiUTuPa-K7"
      },
      "source": [
        "![Links Detector Cover](https://raw.githubusercontent.com/trekhleb/links-detector/master/articles/printed_links_detection/assets/01-banner.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIkPgKIWsHiO"
      },
      "source": [
        "## üìÉ TL;DR\n",
        "\n",
        "- Short problem statement\n",
        "- Short solution\n",
        "- What this article will be about\n",
        "- Links to the demo\n",
        "- GIF image or video of how the app works"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJedZpEkSKYq"
      },
      "source": [
        "_In this article we will try solve the issue of making the printed links (i.e. in a book) clickable via your smartphone camera._\n",
        "\n",
        "We will use [TensorFlow 2 Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection) to train a custom object detector model to find a position of the links in the text image.\n",
        "\n",
        "The following links text recognition will be done by using [Tesseract](https://tesseract.projectnaptha.com/). The recognition part will not be covered in this article but you may see the complete code example in [links-detector repository](https://github.com/trekhleb/links-detector/blob/master/src/hooks/useLinksDetector.ts).   \n",
        "\n",
        "> You may üöÄ [**Launch Links Detector demo**](https://trekhleb.github.io/links-detector/) from your smartphone to see the final result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlkOLNbOsajd"
      },
      "source": [
        "## ü§∑üèª‚Äç‚ôÇÔ∏è The Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucfFZFofSSTx"
      },
      "source": [
        "So you read a book or a magazine and see the links like `https://tensorflow.org/` or `https://some-url.com/which/may/be/longer?and_with_params=true`, but you can't click on them since they are printed. To visit these links you need to start typing them character by character in the browser's address bar, which may be pretty annoying and error prone.\n",
        "\n",
        "![Printed Links](https://raw.githubusercontent.com/trekhleb/links-detector/master/articles/printed_links_detection/assets/02-printed-links.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xj7Gc-KVs4q6"
      },
      "source": [
        "## üí° Possible Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob8k5gcfixDd"
      },
      "source": [
        "Similarly to QR-code detection we may try to \"teach\" the smartphone to _detect_ and _recognize_ printed links for us and also to make them _clickable_. This way you'll do just one click instead of multiple keystrokes. You operational complexity goes from `O(N)` to `O(1)`.\n",
        "\n",
        "![Links Detector Demo](https://raw.githubusercontent.com/trekhleb/links-detector/master/articles/printed_links_detection/assets/03-links-detector-demo.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4orlNJkZs7vB"
      },
      "source": [
        "## üß© Solution Breakdown\n",
        "\n",
        "- Technichal details on how the solution may be achieved\n",
        "- Why TensorFlow, why Object Detection API\n",
        "- Problems that needs to be solved (custom objects, well-known models don't work, small objects, real-time)\n",
        "- Serverless, working on Mobile solution (why no backend? why lightweight model?)\n",
        "- Possible models review, why MobileNet\n",
        "- The issue with the Dataset (there is none)\n",
        "- I'm just learning and don't have too much of experience, wanted to experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VoRXizCNC-d"
      },
      "source": [
        "The task may be split into two parts:\n",
        "\n",
        "1. Links **detection** (the position of the links)\n",
        "2. Links **recognition** (the text of the links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJQpRyWcud-r"
      },
      "source": [
        "## üìù Creating the Dataset Manually\n",
        "\n",
        "- Making pictures of the book\n",
        "- What tools to use to add bounding boxes\n",
        "- How to convert to protobuf\n",
        "- Issues with custom dataset (fonts, colors, bolds, underlined, etc.)\n",
        "- Train/test split approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H9ubdH7ZQqv"
      },
      "source": [
        "### üåÖ Preprocessing the data\n",
        "\n",
        "- Data preprocessing: resize, crop square, color adjustment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_0iXNZPZWLz"
      },
      "source": [
        "### üîñ Labeling the dataset\n",
        "\n",
        "- How to use LabelImg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKZgmaG6Zfbb"
      },
      "source": [
        "### üóú Exporting the dataset\n",
        "\n",
        "- Protobuf (the way of storing the dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLAAnasyvBhS"
      },
      "source": [
        "## üìö Generating the Dataset Automatically (?)\n",
        "\n",
        "- Automated way of generating the dataset\n",
        "- Train/test split approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdk05ymSO7WK"
      },
      "source": [
        "## üìñ Exploring the Dataset\n",
        "\n",
        "- Preview images with detection boxes\n",
        "- Number of images (why is this enough)\n",
        "- Do we need to preprocess the images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0t-B7net2gA"
      },
      "source": [
        "## üõ† Installing Object Detection API \n",
        "\n",
        "- What is object detection API\n",
        "- Why it will simplify our lives\n",
        "- How it may be used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edimSsPB0eaJ",
        "outputId": "4aa6c647-9ab2-4f02-d44b-0e147f4a69dc"
      },
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2305, done.\u001b[K\n",
            "remote: Counting objects: 100% (2305/2305), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2000/2000), done.\u001b[K\n",
            "remote: Total 2305 (delta 562), reused 953 (delta 282), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2305/2305), 30.60 MiB | 31.94 MiB/s, done.\n",
            "Resolving deltas: 100% (562/562), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nQV0aWtuFpV"
      },
      "source": [
        "## ‚¨áÔ∏è Downloading Pre-Trained Model\n",
        "\n",
        "- Model detection Zoo review\n",
        "- What models we could use possibly\n",
        "- Why I've picked the MobileNet model\n",
        "- Diagram of the model architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LpKaPIqPWph"
      },
      "source": [
        "## üèÑüèª‚Äç‚ôÇÔ∏è Trying the Model (Inference)\n",
        "\n",
        "- Show that model works for general purpose classes\n",
        "- Show that model doesn't work for custom objects (links)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7triRLeP-_K"
      },
      "source": [
        "## üìà Setting Up TensorBoard\n",
        "\n",
        "- Why do we need it (for debugging)\n",
        "- What we will monitor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhU74WMHQH1E"
      },
      "source": [
        "## üë®‚Äçüéì Transfer Learning\n",
        "\n",
        "- What is transfer learning\n",
        "- Why don't we train the model from scratch\n",
        "- Allows us to use small dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7nFZjHUQR4A"
      },
      "source": [
        "### ‚öôÔ∏è Configuring the Detection Pipeline\n",
        "\n",
        "- Performance issues: batch size\n",
        "- Starting not from scratch: checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lA_QoEhzQHCT"
      },
      "source": [
        "### üèãüèª‚Äç‚ôÇÔ∏è Model Training\n",
        "\n",
        "- Error prone: saving checkpoints\n",
        "- How many epochs\n",
        "- Monitoring the performance while training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7OZozAHQklI"
      },
      "source": [
        "### üöÄ Evaluating the Model\n",
        "\n",
        "- Checking how accurate our model is on test dataset\n",
        "- Are we good with performance, should we save the model?\n",
        "- It is not a general purpose anymore, does it recognize our custom objects?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMiDAvqTQvg8"
      },
      "source": [
        "## üóú Exporting the Model\n",
        "\n",
        "- Saving the model to the file for further re-use\n",
        "- Show the list of files, how the model looks like on dics\n",
        "- What the size of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlliMpvuQyUz"
      },
      "source": [
        "## üöÄ Evaluating the Exported Model\n",
        "\n",
        "- Example of how to use the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Juyv3FMkQ4qO"
      },
      "source": [
        "## üóú Converting the Model for Web\n",
        "\n",
        "- What formats are sutable for the web\n",
        "- Few words about Tensorflow.js\n",
        "- Show list of exported files - how model looks like on disc\n",
        "- What the size of the model\n",
        "- Why it is split in chucnks and how they are connected (via model.json)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2B8JU1UYzvBy",
        "outputId": "91b29075-0371-4018-e7a9-fbe08fc5055a"
      },
      "source": [
        "pip install tensorflowjs --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 10kB 26.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 20kB 12.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 30kB 9.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 40kB 8.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 51kB 4.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 61kB 5.3MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 4.1MB/s \n",
            "\u001b[?25h\u001b[?25l\r\u001b[K     |‚ñà‚ñà‚ñà‚ñè                            | 10kB 23.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 20kB 20.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                      | 30kB 16.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                   | 40kB 14.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                | 51kB 11.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 61kB 11.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 71kB 7.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç      | 81kB 8.1MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 92kB 8.0MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 102kB 8.2MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 112kB 8.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhqXJkIpRF1A"
      },
      "source": [
        "## ü§î Conclusions\n",
        "\n",
        "- I'm just an amatour\n",
        "- Links to demo app\n",
        "- Issues and limitations of this approach\n",
        "- Links to my ML repositories that thy might like"
      ]
    }
  ]
}